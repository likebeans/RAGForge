# ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æŒ‡å—

**ç‰ˆæœ¬**: 1.0  
**æ—¥æœŸ**: 2026-01-15  
**ç›®æ ‡**: Self-RAG Pipeline ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ¸…å•

---

## ğŸ“‹ éƒ¨ç½²å‰æ£€æŸ¥æ¸…å•

### 1. ç¯å¢ƒé…ç½® âœ…

#### 1.1 åŸºç¡€ç¯å¢ƒ
- [ ] æœåŠ¡å™¨é…ç½®æ£€æŸ¥ï¼ˆCPUã€å†…å­˜ã€ç£ç›˜ï¼‰
- [ ] æ“ä½œç³»ç»Ÿæ›´æ–°åˆ°æœ€æ–°ç¨³å®šç‰ˆ
- [ ] Docker å’Œ Docker Compose å®‰è£…
- [ ] é˜²ç«å¢™é…ç½®ï¼ˆå¼€æ”¾å¿…è¦ç«¯å£ï¼‰
- [ ] SSL/TLS è¯ä¹¦å‡†å¤‡ï¼ˆHTTPSï¼‰

**æ¨èé…ç½®**:
```
æœ€ä½é…ç½®:
- CPU: 4 æ ¸
- å†…å­˜: 16 GB
- ç£ç›˜: 100 GB SSD

æ¨èé…ç½®:
- CPU: 8 æ ¸+
- å†…å­˜: 32 GB+
- ç£ç›˜: 500 GB SSD+
```

#### 1.2 ä¾èµ–æœåŠ¡
- [ ] PostgreSQL 15+ éƒ¨ç½²ï¼ˆæˆ–ä½¿ç”¨äº‘æœåŠ¡ï¼‰
- [ ] Redis 6+ éƒ¨ç½²ï¼ˆç¼“å­˜å’Œé™æµï¼‰
- [ ] Qdrant å‘é‡æ•°æ®åº“éƒ¨ç½²
- [ ] åå‘ä»£ç†é…ç½®ï¼ˆNginx/Caddyï¼‰
- [ ] å¯¹è±¡å­˜å‚¨é…ç½®ï¼ˆå¯é€‰ï¼Œå­˜å‚¨å¤§æ–‡ä»¶ï¼‰

---

### 2. å®‰å…¨é…ç½® ğŸ”’

#### 2.1 å¯†é’¥å’Œä»¤ç‰Œ

**å¿…é¡»ä¿®æ”¹çš„å¯†é’¥**:
```bash
# .env æ–‡ä»¶ä¸­å¿…é¡»ä¿®æ”¹è¿™äº›é…ç½®

# 1. Admin Tokenï¼ˆä½¿ç”¨ API åˆ›å»ºå“ˆå¸Œä»¤ç‰Œï¼‰
ADMIN_TOKEN=<ä½¿ç”¨ Admin Token API ç”Ÿæˆçš„å®‰å…¨ä»¤ç‰Œ>

# 2. æ•°æ®åº“å¯†ç 
DATABASE_URL=postgresql+asyncpg://kb:<å¼ºå¯†ç >@db:5432/kb

# 3. Redis å¯†ç ï¼ˆå¦‚æœå¯ç”¨ï¼‰
REDIS_URL=redis://:<å¼ºå¯†ç >@redis:6379/0

# 4. Qdrant API Keyï¼ˆå¦‚æœå¯ç”¨ï¼‰
QDRANT_API_KEY=<ç”Ÿæˆçš„å®‰å…¨å¯†é’¥>

# 5. æ¨¡å‹æä¾›å•† API Keys
QWEN_API_KEY=<æ‚¨çš„çœŸå® API Key>
OPENAI_API_KEY=<æ‚¨çš„çœŸå® API Key>
GEMINI_API_KEY=<æ‚¨çš„çœŸå® API Key>
```

**ç”Ÿæˆ Admin Token**:
```bash
# 1. å¯åŠ¨æœåŠ¡åï¼Œä½¿ç”¨ä¸´æ—¶ token åˆ›å»ºæ­£å¼çš„ Admin Token
curl -X POST http://localhost:8020/admin/tokens \
  -H "X-Admin-Token: temporary_token_for_first_time" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Production Admin Token",
    "description": "ç”Ÿäº§ç¯å¢ƒç®¡ç†å‘˜ä»¤ç‰Œ",
    "expires_at": null
  }'

# 2. è®°å½•è¿”å›çš„ tokenï¼ˆåªæ˜¾ç¤ºä¸€æ¬¡ï¼ï¼‰
# 3. æ›´æ–° .env æ–‡ä»¶ä¸­çš„ ADMIN_TOKEN
# 4. æ’¤é”€ä¸´æ—¶ token
```

#### 2.2 CORS é…ç½®

**ä¿®æ”¹ `app/main.py`**:
```python
# âŒ å¼€å‘ç¯å¢ƒï¼ˆå…è®¸æ‰€æœ‰æ¥æºï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ä¸å®‰å…¨ï¼
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# âœ… ç”Ÿäº§ç¯å¢ƒï¼ˆé™åˆ¶æ¥æºï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://your-frontend-domain.com",
        "https://app.your-domain.com",
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "PATCH"],
    allow_headers=["*"],
)
```

#### 2.3 API é™æµ

```bash
# .env
API_RATE_LIMIT_PER_MINUTE=600  # ç”Ÿäº§ç¯å¢ƒå¯èƒ½éœ€è¦é™ä½
API_RATE_LIMIT_WINDOW_SECONDS=60

# å¯ç”¨ Redis é™æµï¼ˆæ¨èï¼‰
REDIS_URL=redis://<password>@redis:6379/0
```

#### 2.4 æ•°æ®åº“è¿æ¥æ± 

```bash
# .env
# PostgreSQL è¿æ¥æ± é…ç½®
DB_POOL_SIZE=20              # è¿æ¥æ± å¤§å°
DB_MAX_OVERFLOW=10           # æœ€å¤§æº¢å‡ºè¿æ¥æ•°
DB_POOL_TIMEOUT=30           # è¿æ¥è¶…æ—¶ï¼ˆç§’ï¼‰
DB_POOL_RECYCLE=3600         # è¿æ¥å›æ”¶æ—¶é—´ï¼ˆç§’ï¼‰
```

---

### 3. æ•°æ®åº“å‡†å¤‡ ğŸ’¾

#### 3.1 æ•°æ®åº“è¿ç§»

```bash
# 1. å¤‡ä»½ç°æœ‰æ•°æ®åº“ï¼ˆå¦‚æœæœ‰ï¼‰
pg_dump -h <host> -U kb kb > backup_$(date +%Y%m%d_%H%M%S).sql

# 2. è¿è¡Œè¿ç§»
DATABASE_URL=postgresql+asyncpg://kb:<password>@<host>:5432/kb \
uv run alembic upgrade head

# 3. éªŒè¯è¿ç§»
uv run alembic current
uv run alembic history
```

#### 3.2 æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–

```sql
-- æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
\d+ tenants
\d+ knowledge_bases
\d+ documents
\d+ chunks

-- æ·»åŠ ç”Ÿäº§ç¯å¢ƒæ¨èç´¢å¼•ï¼ˆå¦‚æœç¼ºå¤±ï¼‰
CREATE INDEX CONCURRENTLY idx_chunks_tenant_kb 
ON chunks(tenant_id, knowledge_base_id);

CREATE INDEX CONCURRENTLY idx_documents_tenant_kb 
ON documents(tenant_id, knowledge_base_id);

CREATE INDEX CONCURRENTLY idx_chunks_embedding_status 
ON chunks(indexing_status) WHERE indexing_status != 'indexed';
```

#### 3.3 æ•°æ®åº“ç»´æŠ¤è®¡åˆ’

```sql
-- è®¾ç½®è‡ªåŠ¨ VACUUM
ALTER TABLE chunks SET (autovacuum_vacuum_scale_factor = 0.1);
ALTER TABLE documents SET (autovacuum_vacuum_scale_factor = 0.1);

-- å®šæœŸç»´æŠ¤è„šæœ¬ï¼ˆcron ä»»åŠ¡ï¼‰
-- æ¯å¤©å‡Œæ™¨ 3 ç‚¹æ‰§è¡Œ
-- 0 3 * * * psql -U kb -d kb -c "VACUUM ANALYZE;"
```

---

### 4. å‘é‡æ•°æ®åº“é…ç½® ğŸ”

#### 4.1 Qdrant æŒä¹…åŒ–

```yaml
# docker-compose.yml
services:
  qdrant:
    image: qdrant/qdrant:v1.9.0
    volumes:
      - ./qdrant_data:/qdrant/storage  # æŒä¹…åŒ–å­˜å‚¨
    environment:
      - QDRANT__SERVICE__API_KEY=${QDRANT_API_KEY}  # å¯ç”¨è®¤è¯
    restart: always
```

#### 4.2 å‘é‡åº“å¤‡ä»½

```bash
# Qdrant å¤‡ä»½è„šæœ¬
#!/bin/bash
BACKUP_DIR="/backup/qdrant/$(date +%Y%m%d)"
mkdir -p $BACKUP_DIR

# åˆ›å»ºå¿«ç…§
curl -X POST "http://localhost:6333/collections/kb_shared/snapshots" \
  -H "api-key: $QDRANT_API_KEY"

# ä¸‹è½½å¿«ç…§
curl "http://localhost:6333/collections/kb_shared/snapshots/<snapshot_name>" \
  -H "api-key: $QDRANT_API_KEY" \
  -o "$BACKUP_DIR/kb_shared.snapshot"
```

---

### 5. Redis é…ç½® âš¡

#### 5.1 Redis æŒä¹…åŒ–

```bash
# redis.conf
appendonly yes
appendfilename "appendonly.aof"
save 900 1      # 900ç§’å†…è‡³å°‘1ä¸ªkeyå˜åŒ–å°±ä¿å­˜
save 300 10     # 300ç§’å†…è‡³å°‘10ä¸ªkeyå˜åŒ–å°±ä¿å­˜
save 60 10000   # 60ç§’å†…è‡³å°‘10000ä¸ªkeyå˜åŒ–å°±ä¿å­˜

# å†…å­˜ç­–ç•¥
maxmemory 2gb
maxmemory-policy allkeys-lru
```

#### 5.2 Redis ç›‘æ§

```bash
# å¯ç”¨ Redis ç›‘æ§
redis-cli INFO stats
redis-cli INFO memory
redis-cli SLOWLOG GET 10
```

---

### 6. æ—¥å¿—å’Œç›‘æ§ ğŸ“Š

#### 6.1 æ—¥å¿—é…ç½®

```bash
# .env
LOG_LEVEL=INFO              # ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ INFOï¼ˆä¸è¦ç”¨ DEBUGï¼‰
TIMEZONE=Asia/Shanghai

# æ—¥å¿—è½®è½¬é…ç½®ï¼ˆä½¿ç”¨ logrotateï¼‰
cat > /etc/logrotate.d/rag-pipeline << 'EOF'
/var/log/rag-pipeline/*.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
    postrotate
        docker-compose restart api
    endscript
}
EOF
```

#### 6.2 ç»“æ„åŒ–æ—¥å¿—

ç¡®ä¿æ‰€æœ‰æ—¥å¿—éƒ½æ˜¯ JSON æ ¼å¼ï¼Œä¾¿äºæ—¥å¿—èšåˆå’Œåˆ†æï¼š

```python
# app/infra/logging.py å·²é…ç½®ä¸º JSON æ ¼å¼
# ç¡®ä¿ç”Ÿäº§ç¯å¢ƒä½¿ç”¨æ­£ç¡®çš„æ—¥å¿—çº§åˆ«
```

#### 6.3 ç›‘æ§æŒ‡æ ‡

**å¿…é¡»ç›‘æ§çš„æŒ‡æ ‡**:
1. API å“åº”æ—¶é—´ï¼ˆP50, P95, P99ï¼‰
2. é”™è¯¯ç‡ï¼ˆ4xx, 5xxï¼‰
3. æ•°æ®åº“è¿æ¥æ± ä½¿ç”¨ç‡
4. Redis ç¼“å­˜å‘½ä¸­ç‡
5. ç£ç›˜ä½¿ç”¨ç‡
6. å†…å­˜ä½¿ç”¨ç‡
7. CPU ä½¿ç”¨ç‡

**æ¨èå·¥å…·**:
- Prometheus + Grafana
- ELK Stackï¼ˆElasticsearch + Logstash + Kibanaï¼‰
- äº‘å¹³å°ç›‘æ§ï¼ˆAWS CloudWatch, é˜¿é‡Œäº‘ç›‘æ§ç­‰ï¼‰

---

### 7. åå‘ä»£ç†é…ç½® ğŸŒ

#### 7.1 Nginx é…ç½®ç¤ºä¾‹

```nginx
# /etc/nginx/sites-available/rag-pipeline

upstream rag_api {
    least_conn;
    server localhost:8020 max_fails=3 fail_timeout=30s;
    # å¦‚æœæœ‰å¤šä¸ªå®ä¾‹
    # server localhost:8021 max_fails=3 fail_timeout=30s;
}

server {
    listen 443 ssl http2;
    server_name api.your-domain.com;

    # SSL è¯ä¹¦
    ssl_certificate /etc/letsencrypt/live/api.your-domain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/api.your-domain.com/privkey.pem;

    # SSL é…ç½®
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers on;

    # å®‰å…¨å¤´
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-XSS-Protection "1; mode=block" always;

    # è¯·æ±‚ä½“å¤§å°é™åˆ¶ï¼ˆä¸Šä¼ æ–‡æ¡£ï¼‰
    client_max_body_size 100M;

    # è¶…æ—¶é…ç½®
    proxy_connect_timeout 60s;
    proxy_send_timeout 60s;
    proxy_read_timeout 60s;

    location / {
        proxy_pass http://rag_api;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # WebSocket æ”¯æŒï¼ˆå¦‚æœéœ€è¦ï¼‰
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }

    # å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼ˆä¸éœ€è¦è®¤è¯ï¼‰
    location /health {
        proxy_pass http://rag_api/health;
        access_log off;
    }

    # è®¿é—®æ—¥å¿—
    access_log /var/log/nginx/rag-pipeline-access.log;
    error_log /var/log/nginx/rag-pipeline-error.log;
}

# HTTP é‡å®šå‘åˆ° HTTPS
server {
    listen 80;
    server_name api.your-domain.com;
    return 301 https://$server_name$request_uri;
}
```

#### 7.2 Caddy é…ç½®ç¤ºä¾‹ï¼ˆæ›´ç®€å•ï¼‰

```caddyfile
# Caddyfile

api.your-domain.com {
    reverse_proxy localhost:8020
    
    # è‡ªåŠ¨ HTTPS
    tls your-email@example.com
    
    # å®‰å…¨å¤´
    header {
        Strict-Transport-Security "max-age=31536000; includeSubDomains"
        X-Content-Type-Options "nosniff"
        X-Frame-Options "SAMEORIGIN"
        X-XSS-Protection "1; mode=block"
    }
    
    # è¯·æ±‚ä½“å¤§å°é™åˆ¶
    request_body {
        max_size 100MB
    }
}
```

---

### 8. Docker ç”Ÿäº§é…ç½® ğŸ³

#### 8.1 ä¼˜åŒ– docker-compose.yml

```yaml
version: '3.8'

services:
  db:
    image: postgres:15
    environment:
      POSTGRES_DB: kb
      POSTGRES_USER: kb
      POSTGRES_PASSWORD: ${DB_PASSWORD}  # ä»ç¯å¢ƒå˜é‡è¯»å–
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U kb"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    command: redis-server --requirepass ${REDIS_PASSWORD} --appendonly yes
    volumes:
      - redis_data:/data
    restart: always
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  qdrant:
    image: qdrant/qdrant:v1.9.0
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      QDRANT__SERVICE__API_KEY: ${QDRANT_API_KEY}
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  api:
    build:
      context: .
      dockerfile: Dockerfile
      network: host  # åŠ é€Ÿæ„å»º
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      qdrant:
        condition: service_healthy
    env_file:
      - .env
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8020/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    depends_on:
      - api
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  qdrant_data:
    driver: local

networks:
  default:
    name: rag_pipeline_network
```

#### 8.2 ä¼˜åŒ– Dockerfile

```dockerfile
# å¤šé˜¶æ®µæ„å»ºï¼Œå‡å°é•œåƒä½“ç§¯
FROM python:3.11-slim as builder

WORKDIR /app

# å®‰è£… uv
RUN pip install uv

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY pyproject.toml uv.lock ./

# å®‰è£…ä¾èµ–åˆ°è™šæ‹Ÿç¯å¢ƒ
RUN uv sync --no-dev

# è¿è¡Œé˜¶æ®µ
FROM python:3.11-slim

WORKDIR /app

# å¤åˆ¶ä¾èµ–
COPY --from=builder /app/.venv /app/.venv

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY app ./app
COPY alembic ./alembic
COPY alembic.ini ./
COPY scripts ./scripts

# åˆ›å»ºé root ç”¨æˆ·
RUN useradd -m -u 1000 appuser && \
    chown -R appuser:appuser /app

USER appuser

# å¯åŠ¨è„šæœ¬
CMD ["/app/.venv/bin/uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8020"]
```

---

### 9. å¤‡ä»½ç­–ç•¥ ğŸ’¾

#### 9.1 è‡ªåŠ¨å¤‡ä»½è„šæœ¬

```bash
#!/bin/bash
# /opt/backup/rag-pipeline-backup.sh

set -e

BACKUP_DIR="/backup/rag-pipeline"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR/{postgres,qdrant,config}

# 1. PostgreSQL å¤‡ä»½
echo "å¤‡ä»½ PostgreSQL..."
docker exec rag_kb_postgres pg_dump -U kb kb | gzip > \
    $BACKUP_DIR/postgres/kb_${DATE}.sql.gz

# 2. Qdrant å¤‡ä»½
echo "å¤‡ä»½ Qdrant..."
tar -czf $BACKUP_DIR/qdrant/qdrant_${DATE}.tar.gz \
    ./qdrant_data/

# 3. é…ç½®æ–‡ä»¶å¤‡ä»½
echo "å¤‡ä»½é…ç½®..."
cp .env $BACKUP_DIR/config/.env_${DATE}
cp docker-compose.yml $BACKUP_DIR/config/docker-compose_${DATE}.yml

# 4. åˆ é™¤æ—§å¤‡ä»½
echo "æ¸…ç†æ—§å¤‡ä»½..."
find $BACKUP_DIR -type f -mtime +$RETENTION_DAYS -delete

# 5. ä¸Šä¼ åˆ°å¯¹è±¡å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
# aws s3 sync $BACKUP_DIR s3://your-backup-bucket/rag-pipeline/

echo "å¤‡ä»½å®Œæˆ: $DATE"
```

#### 9.2 å®šæ—¶ä»»åŠ¡

```bash
# crontab -e
# æ¯å¤©å‡Œæ™¨ 2 ç‚¹å¤‡ä»½
0 2 * * * /opt/backup/rag-pipeline-backup.sh >> /var/log/backup.log 2>&1
```

---

### 10. æ€§èƒ½ä¼˜åŒ– âš¡

#### 10.1 Redis ç¼“å­˜é…ç½®

```bash
# .env
REDIS_CACHE_ENABLED=true
REDIS_CACHE_TTL=300           # æŸ¥è¯¢ç¼“å­˜ 5 åˆ†é’Ÿ
REDIS_CONFIG_CACHE_TTL=600    # é…ç½®ç¼“å­˜ 10 åˆ†é’Ÿ
```

#### 10.2 BM25 é™åˆ¶

```bash
# .env
BM25_MAX_RECORDS_PER_KB=10000
BM25_MAX_TOTAL_RECORDS=100000
```

#### 10.3 è¿æ¥æ± ä¼˜åŒ–

```python
# app/db/session.py
engine = create_async_engine(
    settings.database_url,
    pool_size=20,              # ç”Ÿäº§ç¯å¢ƒå¢åŠ æ± å¤§å°
    max_overflow=10,
    pool_timeout=30,
    pool_recycle=3600,
    pool_pre_ping=True,        # æ£€æŸ¥è¿æ¥æœ‰æ•ˆæ€§
)
```

---

### 11. å¥åº·æ£€æŸ¥å’Œæ¢å¤ ğŸ¥

#### 11.1 å¥åº·æ£€æŸ¥ç«¯ç‚¹

ç¡®ä¿ `/health` ç«¯ç‚¹è¿”å›è¯¦ç»†ä¿¡æ¯ï¼š

```python
# app/api/routes/health.py
@router.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0",
        "services": {
            "database": await check_db(),
            "redis": await check_redis(),
            "qdrant": await check_qdrant(),
        }
    }
```

#### 11.2 ç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# /opt/monitor/check-health.sh

API_URL="http://localhost:8020/health"
ALERT_EMAIL="admin@example.com"

response=$(curl -s -o /dev/null -w "%{http_code}" $API_URL)

if [ $response -ne 200 ]; then
    echo "API å¥åº·æ£€æŸ¥å¤±è´¥! HTTP $response" | \
        mail -s "RAG Pipeline Alert" $ALERT_EMAIL
    
    # å°è¯•é‡å¯æœåŠ¡
    docker-compose restart api
fi
```

---

### 12. å®‰å…¨åŠ å›º ğŸ”

#### 12.1 é˜²ç«å¢™è§„åˆ™

```bash
# UFW ç¤ºä¾‹
ufw default deny incoming
ufw default allow outgoing
ufw allow 22/tcp      # SSH
ufw allow 80/tcp      # HTTP
ufw allow 443/tcp     # HTTPS
ufw enable
```

#### 12.2 SSH åŠ å›º

```bash
# /etc/ssh/sshd_config
PermitRootLogin no
PasswordAuthentication no
PubkeyAuthentication yes
Port 2222  # ä¿®æ”¹é»˜è®¤ç«¯å£
```

#### 12.3 æ•æ„Ÿæ–‡ä»¶æƒé™

```bash
chmod 600 .env
chmod 600 alembic.ini
chown appuser:appuser .env
```

---

### 13. éƒ¨ç½²æ£€æŸ¥æ¸…å• âœ…

#### å¯åŠ¨å‰æ£€æŸ¥
- [ ] æ‰€æœ‰å¯†é’¥å·²ä¿®æ”¹ï¼ˆAdmin Token, DB å¯†ç , Redis å¯†ç ç­‰ï¼‰
- [ ] CORS å·²é™åˆ¶åˆ°å…·ä½“åŸŸå
- [ ] SSL è¯ä¹¦å·²é…ç½®
- [ ] æ•°æ®åº“è¿ç§»å·²å®Œæˆ
- [ ] å¤‡ä»½è„šæœ¬å·²é…ç½®
- [ ] ç›‘æ§å·²å¯ç”¨
- [ ] æ—¥å¿—è½®è½¬å·²é…ç½®
- [ ] é˜²ç«å¢™è§„åˆ™å·²è®¾ç½®
- [ ] å¥åº·æ£€æŸ¥å·²æµ‹è¯•

#### å¯åŠ¨åæ£€æŸ¥
- [ ] æ‰€æœ‰æœåŠ¡å®¹å™¨è¿è¡Œæ­£å¸¸
- [ ] æ•°æ®åº“è¿æ¥æ­£å¸¸
- [ ] Redis ç¼“å­˜æ­£å¸¸
- [ ] Qdrant å‘é‡åº“æ­£å¸¸
- [ ] API å¥åº·æ£€æŸ¥è¿”å› 200
- [ ] å‰ç«¯å¯ä»¥è®¿é—®
- [ ] æ—¥å¿—æ­£å¸¸è¾“å‡º
- [ ] åˆ›å»ºæµ‹è¯•ç§Ÿæˆ·æˆåŠŸ
- [ ] åˆ›å»ºæµ‹è¯•çŸ¥è¯†åº“æˆåŠŸ
- [ ] ä¸Šä¼ æµ‹è¯•æ–‡æ¡£æˆåŠŸ
- [ ] æ£€ç´¢æµ‹è¯•æˆåŠŸ
- [ ] RAG ç”Ÿæˆæµ‹è¯•æˆåŠŸ

---

### 14. è¿ç»´æ–‡æ¡£ ğŸ“š

#### 14.1 å¸¸è§é—®é¢˜æ’æŸ¥

**æ•°æ®åº“è¿æ¥å¤±è´¥**:
```bash
# æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
docker-compose ps db
docker logs rag_kb_postgres

# æµ‹è¯•è¿æ¥
psql -h localhost -p 5435 -U kb -d kb
```

**Redis è¿æ¥å¤±è´¥**:
```bash
# æ£€æŸ¥ Redis çŠ¶æ€
docker-compose ps redis
docker logs rag_kb_redis

# æµ‹è¯•è¿æ¥
redis-cli -h localhost -p 6379 -a <password> PING
```

**å‘é‡åº“åŒæ­¥é—®é¢˜**:
```bash
# æ£€æŸ¥ Qdrant çŠ¶æ€
curl http://localhost:6333/collections

# æŸ¥çœ‹ collection ä¿¡æ¯
curl http://localhost:6333/collections/kb_shared
```

#### 14.2 ç´§æ€¥å›æ»š

```bash
# 1. åœæ­¢æœåŠ¡
docker-compose down

# 2. æ¢å¤æ•°æ®åº“
gunzip -c /backup/postgres/kb_<date>.sql.gz | \
    docker exec -i rag_kb_postgres psql -U kb kb

# 3. æ¢å¤ Qdrant
tar -xzf /backup/qdrant/qdrant_<date>.tar.gz -C ./

# 4. æ¢å¤é…ç½®
cp /backup/config/.env_<date> .env

# 5. é‡å¯æœåŠ¡
docker-compose up -d
```

---

### 15. æ‰©å±•æ€§è§„åˆ’ ğŸ“ˆ

#### 15.1 æ°´å¹³æ‰©å±•

**API å¤šå®ä¾‹éƒ¨ç½²**:
```yaml
# docker-compose.yml
services:
  api1:
    <<: *api-common
    ports:
      - "8020:8020"
  
  api2:
    <<: *api-common
    ports:
      - "8021:8020"
  
  api3:
    <<: *api-common
    ports:
      - "8022:8020"
```

**Nginx è´Ÿè½½å‡è¡¡**:
```nginx
upstream rag_api {
    least_conn;
    server localhost:8020;
    server localhost:8021;
    server localhost:8022;
}
```

#### 15.2 è¯»å†™åˆ†ç¦»

PostgreSQL ä¸»ä»å¤åˆ¶é…ç½®ï¼ˆå¯é€‰ï¼‰ã€‚

---

## ğŸš€ å¿«é€Ÿéƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# deploy.sh - ä¸€é”®éƒ¨ç½²è„šæœ¬

set -e

echo "ğŸš€ å¼€å§‹éƒ¨ç½² RAG Pipeline..."

# 1. æ£€æŸ¥ä¾èµ–
echo "æ£€æŸ¥ä¾èµ–..."
command -v docker >/dev/null 2>&1 || { echo "éœ€è¦å®‰è£… Docker"; exit 1; }
command -v docker-compose >/dev/null 2>&1 || { echo "éœ€è¦å®‰è£… Docker Compose"; exit 1; }

# 2. å¤‡ä»½ç°æœ‰æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
if [ -f .env ]; then
    echo "å¤‡ä»½ç°æœ‰é…ç½®..."
    cp .env .env.backup.$(date +%Y%m%d_%H%M%S)
fi

# 3. é…ç½®ç¯å¢ƒå˜é‡
if [ ! -f .env ]; then
    echo "åˆ›å»º .env æ–‡ä»¶..."
    cp .env.example .env
    echo "è¯·ç¼–è¾‘ .env æ–‡ä»¶ï¼Œä¿®æ”¹æ‰€æœ‰å¯†é’¥å’Œé…ç½®"
    exit 1
fi

# 4. æ‹‰å–æœ€æ–°é•œåƒ
echo "æ‹‰å– Docker é•œåƒ..."
docker-compose pull

# 5. æ„å»ºåº”ç”¨
echo "æ„å»ºåº”ç”¨..."
docker-compose build --no-cache

# 6. å¯åŠ¨æœåŠ¡
echo "å¯åŠ¨æœåŠ¡..."
docker-compose up -d

# 7. ç­‰å¾…æœåŠ¡å°±ç»ª
echo "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 30

# 8. è¿è¡Œæ•°æ®åº“è¿ç§»
echo "è¿è¡Œæ•°æ®åº“è¿ç§»..."
docker-compose exec api uv run alembic upgrade head

# 9. å¥åº·æ£€æŸ¥
echo "å¥åº·æ£€æŸ¥..."
curl -f http://localhost:8020/health || { echo "å¥åº·æ£€æŸ¥å¤±è´¥"; exit 1; }

echo "âœ… éƒ¨ç½²å®Œæˆï¼"
echo "API: http://localhost:8020"
echo "Frontend: http://localhost:3003"
echo ""
echo "ä¸‹ä¸€æ­¥:"
echo "1. åˆ›å»º Admin Token"
echo "2. é…ç½® Nginx åå‘ä»£ç†"
echo "3. é…ç½® SSL è¯ä¹¦"
echo "4. è®¾ç½®å®šæ—¶å¤‡ä»½"
```

---

## ğŸ“ æ”¯æŒå’Œè”ç³»

å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒï¼š
- é¡¹ç›®æ–‡æ¡£: `/docs`
- å¥åº·æ£€æŸ¥: `http://your-domain.com/health`
- æ—¥å¿—ä½ç½®: `/var/log/rag-pipeline/`

---

**æœ€åæ›´æ–°**: 2026-01-15
