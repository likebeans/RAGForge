# Self-RAG Pipeline 配置示例
# 复制此文件为 .env 并根据需要修改

# ==================== 基础配置 ====================
DATABASE_URL=postgresql+asyncpg://kb:kb@localhost:5435/kb
APP_NAME="RAG Pipeline Service"
ENVIRONMENT=dev
TIMEZONE=Asia/Shanghai
API_RATE_LIMIT_PER_MINUTE=120
API_RATE_LIMIT_WINDOW_SECONDS=60
API_KEY_PREFIX=kb_sk_

# ==================== 向量数据库 ====================
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=

# ==================== 模型提供商 API Keys ====================
# Ollama（本地部署，无需 API Key）
OLLAMA_BASE_URL=http://localhost:11434

# OpenAI
# OPENAI_API_KEY=sk-xxx
# OPENAI_API_BASE=https://api.openai.com/v1

# Google Gemini
# GEMINI_API_KEY=AIzaSyXXXXXXXXXXXXXXXXX

# 阿里云通义千问 (DashScope)
# QWEN_API_KEY=sk-xxx

# 月之暗面 Kimi (Moonshot)
# KIMI_API_KEY=sk-xxx

# DeepSeek
# DEEPSEEK_API_KEY=sk-xxx

# 智谱 AI (GLM)
# ZHIPU_API_KEY=xxx

# SiliconFlow
# SILICONFLOW_API_KEY=sk-xxx

# Cohere (Rerank)
# COHERE_API_KEY=xxx

# ==================== LLM 配置 ====================
# provider: ollama / openai / gemini / qwen / kimi / deepseek / zhipu / siliconflow
LLM_PROVIDER=ollama
LLM_MODEL=qwen3:14b
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2048

# ==================== Embedding 配置 ====================
# provider: ollama / openai / gemini / qwen / zhipu / siliconflow
EMBEDDING_PROVIDER=ollama
EMBEDDING_MODEL=bge-m3
EMBEDDING_DIM=1024
# 常见维度：
# - OpenAI text-embedding-3-small: 1536
# - BGE-M3: 1024
# - Gemini text-embedding-004: 768

# ==================== Rerank 配置 ====================
# provider: ollama / cohere / zhipu / siliconflow / none
RERANK_PROVIDER=none
RERANK_MODEL=
RERANK_TOP_K=10

# ==================== 功能开关 ====================
HYDE_ENABLED=false
DOC_SUMMARY_ENABLED=false
CHUNK_ENRICHMENT_ENABLED=false

# ==================== 其他存储（可选）====================
# Milvus
# MILVUS_HOST=localhost
# MILVUS_PORT=19530

# Elasticsearch
# ES_HOSTS=http://localhost:9200
# ES_INDEX_PREFIX=kb_
