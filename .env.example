# =============================================================================
# 配置文件说明
# =============================================================================
# .env.example  - 配置模板（包含所有可用选项和说明，提交到 Git）
# .env          - Docker/生产环境默认配置（提交到 Git）
# .env.local    - 本地开发覆盖配置（包含真实密钥，不提交到 Git）
#
# 使用方法：
# 1. 复制本文件为 .env：cp .env.example .env
# 2. 创建 .env.local 用于本地开发（可选）
# 3. 修改相应配置项的值
# =============================================================================

# =============================================================================
# 基础配置
# =============================================================================
# 应用名称
APP_NAME="RAG Pipeline Service"

# 运行环境：dev/staging/production
ENVIRONMENT=dev

# 数据库连接 URL
# 格式：postgresql+asyncpg://用户名:密码@主机:端口/数据库名
# Docker 环境：postgresql+asyncpg://kb:kb@db:5432/kb
# 本地开发：postgresql+asyncpg://kb:kb@localhost:5435/kb
DATABASE_URL=postgresql+asyncpg://kb:kb@db:5432/kb

# API 密钥前缀（用于生成 API Key）
API_KEY_PREFIX=kb_sk_

# =============================================================================
# API 限流配置
# =============================================================================
# 每分钟请求次数限制
API_RATE_LIMIT_PER_MINUTE=600

# 限流时间窗口（秒）
API_RATE_LIMIT_WINDOW_SECONDS=60

# =============================================================================
# 向量存储配置
# =============================================================================
# 向量存储类型：postgresql（使用 pgvector）
VECTOR_STORE=postgresql

# =============================================================================
# Redis 配置（限流 + 缓存）
# =============================================================================
# Redis 连接 URL
# 格式：redis://[:password]@host:port/db
# Docker 环境：redis://redis:6379/0
# 本地开发：redis://localhost:6389/0
REDIS_URL=redis://redis:6379/0

# 是否启用 Redis 查询缓存
REDIS_CACHE_ENABLED=true

# 查询结果缓存过期时间（秒）
REDIS_CACHE_TTL=300

# 缓存键前缀
REDIS_CACHE_KEY_PREFIX=rag:cache:

# 知识库配置缓存过期时间（秒）
REDIS_CONFIG_CACHE_TTL=600

# =============================================================================
# 模型提供商 - Ollama（本地部署）
# =============================================================================
# Ollama 服务地址
# Docker 环境：http://host.docker.internal:11434（访问宿主机）
# 本地开发：http://localhost:11434
OLLAMA_BASE_URL=http://host.docker.internal:11434

# =============================================================================
# 模型提供商 - OpenAI
# =============================================================================
# OpenAI API 密钥
OPENAI_API_KEY=sk-your_openai_api_key_here

# OpenAI API 基础 URL
OPENAI_API_BASE=https://api.openai.com/v1

# 默认使用的 OpenAI 模型
OPENAI_MODEL=gpt-4o

# =============================================================================
# 模型提供商 - Google Gemini
# =============================================================================
GEMINI_API_KEY=your_gemini_api_key_here

# =============================================================================
# 模型提供商 - 阿里云通义千问
# =============================================================================
QWEN_API_KEY=sk-your_qwen_api_key_here

# =============================================================================
# 模型提供商 - 月之暗面 Kimi（可选）
# =============================================================================
# KIMI_API_KEY=your_kimi_api_key_here

# =============================================================================
# 模型提供商 - DeepSeek（可选）
# =============================================================================
# DEEPSEEK_API_KEY=your_deepseek_api_key_here

# =============================================================================
# 模型提供商 - 智谱 AI（可选）
# =============================================================================
# ZHIPU_API_KEY=your_zhipu_api_key_here

# =============================================================================
# 模型提供商 - SiliconFlow（可选）
# =============================================================================
# SILICONFLOW_API_KEY=your_siliconflow_api_key_here
# SILICONFLOW_API_BASE=https://api.siliconflow.cn/v1

# =============================================================================
# LLM 配置
# =============================================================================
# LLM 提供商：ollama/openai/gemini/qwen/kimi/deepseek/zhipu/siliconflow
LLM_PROVIDER=ollama

# LLM 模型名称
LLM_MODEL=qwen2.5:14b

# 生成温度（0-1，越大越随机）
LLM_TEMPERATURE=0.7

# 最大生成 Token 数
LLM_MAX_TOKENS=2048

# =============================================================================
# Embedding 配置
# =============================================================================
# Embedding 提供商：ollama/openai/gemini/qwen/zhipu/siliconflow
EMBEDDING_PROVIDER=ollama

# Embedding 模型名称
EMBEDDING_MODEL=bge-m3

# Embedding 维度
EMBEDDING_DIM=1024

# =============================================================================
# Rerank 配置
# =============================================================================
# Rerank 提供商：ollama/zhipu/siliconflow/cohere/none
RERANK_PROVIDER=ollama

# Rerank 模型名称
RERANK_MODEL=bge-reranker-large

# Rerank Top-K（重排序前保留的候选数）
RERANK_TOP_K=10

# =============================================================================
# HyDE 配置（假设文档嵌入）
# =============================================================================
# 是否启用 HyDE
HYDE_ENABLED=true

# 生成的假设文档数量
HYDE_NUM_QUERIES=3

# 是否包含原始查询
HYDE_INCLUDE_ORIGINAL=true

# HyDE 生成最大 Token 数
HYDE_MAX_TOKENS=2000

# =============================================================================
# BM25 存储配置
# =============================================================================
# 每个知识库最多保存的 BM25 记录数
BM25_MAX_RECORDS_PER_KB=10000

# 全局最多保存的 BM25 记录数
BM25_MAX_TOTAL_RECORDS=100000

# =============================================================================
# 管理员配置
# =============================================================================
# 管理员 API Token（用于调用 /admin/* 接口）
# 建议使用强随机字符串，例如：openssl rand -base64 32
ADMIN_TOKEN=your_secure_admin_token_here

# =============================================================================
# 日志配置
# =============================================================================
# 日志级别：DEBUG/INFO/WARNING/ERROR/CRITICAL
LOG_LEVEL=INFO

# 时区设置
TIMEZONE=Asia/Shanghai
